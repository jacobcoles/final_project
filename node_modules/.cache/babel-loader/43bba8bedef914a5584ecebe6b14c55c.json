{"ast":null,"code":"import _regeneratorRuntime from \"/Users/jacobcoles/Desktop/LT2216/final_project/final_project/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _slicedToArray from \"/Users/jacobcoles/Desktop/LT2216/final_project/final_project/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _asyncToGenerator from \"/Users/jacobcoles/Desktop/LT2216/final_project/final_project/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _objectSpread from \"/Users/jacobcoles/Desktop/LT2216/final_project/final_project/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/objectSpread2\";\n\nvar _jsxFileName = \"/Users/jacobcoles/Desktop/LT2216/final_project/final_project/src/index.tsx\",\n    _s = $RefreshSig$();\n\nimport \"./styles.scss\";\nimport * as React from \"react\";\nimport * as ReactDOM from \"react-dom\";\nimport { Machine, assign, actions } from \"xstate\";\nconst send = actions.send,\n      cancel = actions.cancel;\nimport { useMachine, asEffect } from \"@xstate/react\";\nimport { inspect } from \"@xstate/inspect\";\nimport { dmMachine } from \"./final_project\";\ninspect({\n  url: \"https://statecharts.io/inspect\",\n  iframe: false\n});\nimport { useSpeechSynthesis, useSpeechRecognition } from 'react-speech-kit';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst machine = Machine({\n  id: 'root',\n  type: 'parallel',\n  states: {\n    dm: _objectSpread({}, dmMachine),\n    asrtts: {\n      initial: 'idle',\n      states: {\n        idle: {\n          on: {\n            LISTEN: 'recognising',\n            SPEAK: {\n              target: 'speaking',\n              actions: assign((_context, event) => {\n                return {\n                  ttsAgenda: event.value\n                };\n              })\n            }\n          }\n        },\n        recognising: {\n          initial: 'progress',\n          entry: 'recStart',\n          exit: 'recStop',\n          on: {\n            ASRRESULT: {\n              actions: ['recLogResult', assign((_context, event) => {\n                return {\n                  recResult: event.value.toLowerCase()\n                };\n              })],\n              target: '.match'\n            },\n            RECOGNISED: {\n              actions: [cancel('maxspeech_cancel') //assign((_context, event) => { return { maxspeech_count: 0 } })\n              ],\n              target: 'idle'\n            },\n            MAXSPEECH: [//{\n            //\tcond: context=> context.maxspeech_count < 2,\n            //\ttarget:'idle',\n            //\tactions: assign((_context, event) => { return { maxspeech_count: _context.maxspeech_count +1 } }),\n            //},\n            {\n              target: 'idle' //actions: assign((_context, event) => { return { maxspeech_count: 0 } }),\n\n            }]\n          },\n          states: {\n            progress: {},\n            match: {\n              entry: send('RECOGNISED')\n            }\n          }\n        },\n        speaking: {\n          entry: 'ttsStart',\n          on: {\n            ENDSPEECH: 'idle'\n          }\n        }\n      }\n    }\n  }\n}, {\n  actions: {\n    recLogResult: context => {\n      /* context.recResult = event.recResult; */\n      console.log('<< ASR: ' + context.recResult);\n    },\n    test: () => {\n      console.log('test');\n    },\n    logIntent: context => {\n      /* context.nluData = event.data */\n      console.log('<< NLU intent: ' + context.nluData.intent.name);\n    }\n  }\n});\n\nconst ReactiveButton = props => {\n  switch (true) {\n    case props.state.matches({\n      asrtts: 'recognising'\n    }):\n      return /*#__PURE__*/_jsxDEV(\"button\", _objectSpread(_objectSpread({\n        type: \"button\",\n        className: \"glow-on-hover\",\n        style: {\n          animation: \"glowing 20s linear\"\n        }\n      }, props), {}, {\n        children: \"Listening...\"\n      }), void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 110,\n        columnNumber: 17\n      }, this);\n\n    case props.state.matches({\n      asrtts: 'speaking'\n    }):\n      return /*#__PURE__*/_jsxDEV(\"button\", _objectSpread(_objectSpread({\n        type: \"button\",\n        className: \"glow-on-hover\",\n        style: {\n          animation: \"bordering 1s infinite\"\n        }\n      }, props), {}, {\n        children: \"Speaking...\"\n      }), void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 117,\n        columnNumber: 17\n      }, this);\n\n    default:\n      return /*#__PURE__*/_jsxDEV(\"button\", _objectSpread(_objectSpread({\n        type: \"button\",\n        className: \"glow-on-hover\"\n      }, props), {}, {\n        children: \"Click to start\"\n      }), void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 124,\n        columnNumber: 17\n      }, this);\n  }\n};\n/*\nvar SpeechGrammarList = SpeechGrammarList || webkitSpeechGrammarList\nvar letters = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z'];\nvar grammar = '#JSGF V1.0; grammar letters; public <letter> = ' + letters.join(' | ') + ' ;'\nvar speechRecognitionList = new SpeechGrammarList();\nspeechRecognitionList.addFromString(grammar, 1);\n*/\n\n\n_c = ReactiveButton;\n\nconst _require = require('google-auth-library'),\n      JWT = _require.JWT;\n\nconst keys = require('./el_goog_cred.json');\n\nfunction main() {\n  return _main.apply(this, arguments);\n}\n\nfunction _main() {\n  _main = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n    var client, url, res;\n    return _regeneratorRuntime.wrap(function _callee$(_context2) {\n      while (1) switch (_context2.prev = _context2.next) {\n        case 0:\n          client = new JWT({\n            email: keys.client_email,\n            key: keys.private_key,\n            scopes: ['https://www.googleapis.com/auth/cloud-platform']\n          });\n          url = \"https://dns.googleapis.com/dns/v1/projects/\".concat(keys.project_id);\n          _context2.next = 4;\n          return client.request({\n            url\n          });\n\n        case 4:\n          res = _context2.sent;\n          console.log(res.data);\n\n        case 6:\n        case \"end\":\n          return _context2.stop();\n      }\n    }, _callee);\n  }));\n  return _main.apply(this, arguments);\n}\n\nmain().catch(console.error);\n\nconst recorder = require('node-record-lpcm16'); // Imports the Google Cloud client library\n\n\nconst speech = require('@google-cloud/speech'); // Creates a client\n\n\nconst client = new speech.SpeechClient();\nconst encoding = 'LINEAR16';\nconst sampleRateHertz = 16000;\nconst languageCode = 'en-AU';\nconst request = {\n  config: {\n    encoding: encoding,\n    sampleRateHertz: sampleRateHertz,\n    languageCode: languageCode\n  },\n  interimResults: false // If you want interim results, set this to true\n\n}; // Create a recognize stream\n\nconst recognizeStream = client.streamingRecognize(request).on('error', console.error).on('data', data => process.stdout.write(data.results[0] && data.results[0].alternatives[0] ? \"Transcription: \".concat(data.results[0].alternatives[0].transcript, \"\\n\") : '\\n\\nReached transcription time limit, press Ctrl+C\\n')); // Start recording and send the microphone input to the Speech API.\n// Ensure SoX is installed, see https://www.npmjs.com/package/node-record-lpcm16#dependencies\n\nrecorder.record({\n  sampleRateHertz: sampleRateHertz,\n  threshold: 0,\n  // Other options, see https://www.npmjs.com/package/node-record-lpcm16#options\n  verbose: false,\n  recordProgram: 'rec',\n  // Try also \"arecord\" or \"sox\"\n  silence: '10.0'\n}).stream().on('error', console.error).pipe(recognizeStream);\nconsole.log('Listening, press Ctrl+C to stop.');\n\nfunction App() {\n  _s();\n\n  const _useSpeechSynthesis = useSpeechSynthesis({\n    onEnd: () => {\n      send('ENDSPEECH');\n    }\n  }),\n        speak = _useSpeechSynthesis.speak,\n        cancel = _useSpeechSynthesis.cancel,\n        speaking = _useSpeechSynthesis.speaking,\n        voices = _useSpeechSynthesis.voices;\n\n  const _useSpeechRecognition = useSpeechRecognition({\n    onResult: result => {\n      send({\n        type: \"ASRRESULT\",\n        value: result\n      });\n      console.log(result);\n    }\n  }),\n        listen = _useSpeechRecognition.listen,\n        listening = _useSpeechRecognition.listening,\n        stop = _useSpeechRecognition.stop;\n\n  const _useMachine = useMachine(machine, {\n    devTools: true,\n    actions: {\n      recStart: asEffect(() => {\n        console.log('LETS GOOOOOO');\n        listen({\n          lang: 'en-AU',\n          interimResults: false,\n          continuous: true //grammars: speechRecognitionList,\n\n        });\n      }),\n      recStop: asEffect(() => {\n        console.log('Recognition stopped.');\n        stop();\n      }),\n      changeColour: asEffect(context => {\n        console.log('Repainting...');\n        document.body.style.background = context.recResult;\n      }),\n      ttsStart: asEffect((context, effect) => {\n        console.log('Speaking...');\n        speak({\n          text: context.ttsAgenda,\n          voice: voices[0]\n        });\n      }),\n      ttsCancel: asEffect((context, effect) => {\n        console.log('TTS STOP...');\n        cancel();\n      })\n      /* speak: asEffect((context) => {\n      * console.log('Speaking...');\n       *     speak({text: context.ttsAgenda })\n       * } */\n\n    }\n  }),\n        _useMachine2 = _slicedToArray(_useMachine, 3),\n        current = _useMachine2[0],\n        send = _useMachine2[1],\n        service = _useMachine2[2];\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      className: \"scoring\",\n      children: current.context.ttsAgenda || 'Welcome'\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 260,\n      columnNumber: 4\n    }, this), /*#__PURE__*/_jsxDEV(ReactiveButton, {\n      state: current,\n      onClick: () => send('CLICK')\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 263,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 259,\n    columnNumber: 9\n  }, this);\n}\n\n_s(App, \"89sEhUJEBvjb3/lj6V2w6e7mGZ0=\", false, function () {\n  return [useSpeechSynthesis, useSpeechRecognition, useMachine];\n});\n\n_c2 = App;\n; //<img src={potato} alt=\"potato\" height={300} width={200} />\n//RASA\n\nconst proxyurl = \"https://cors-anywhere.herokuapp.com/\";\nconst rasaurl = 'https://rasajacobcoles.herokuapp.com/model/parse';\n\nconst nluRequest = text => fetch(new Request(proxyurl + rasaurl, {\n  method: 'POST',\n  headers: {\n    'Origin': 'http://maraev.me'\n  },\n  // only required with proxy\n  body: \"{\\\"text\\\": \\\"\".concat(text, \"\\\"}\")\n})).then(data => data.json());\n\nconst rootElement = document.getElementById(\"root\");\nReactDOM.render( /*#__PURE__*/_jsxDEV(App, {}, void 0, false, {\n  fileName: _jsxFileName,\n  lineNumber: 285,\n  columnNumber: 5\n}, this), rootElement);\n\nvar _c, _c2;\n\n$RefreshReg$(_c, \"ReactiveButton\");\n$RefreshReg$(_c2, \"App\");","map":{"version":3,"sources":["/Users/jacobcoles/Desktop/LT2216/final_project/final_project/src/index.tsx"],"names":["React","ReactDOM","Machine","assign","actions","send","cancel","useMachine","asEffect","inspect","dmMachine","url","iframe","useSpeechSynthesis","useSpeechRecognition","machine","id","type","states","dm","asrtts","initial","idle","on","LISTEN","SPEAK","target","_context","event","ttsAgenda","value","recognising","entry","exit","ASRRESULT","recResult","toLowerCase","RECOGNISED","MAXSPEECH","progress","match","speaking","ENDSPEECH","recLogResult","context","console","log","test","logIntent","nluData","intent","name","ReactiveButton","props","state","matches","animation","require","JWT","keys","main","client","email","client_email","key","private_key","scopes","project_id","request","res","data","catch","error","recorder","speech","SpeechClient","encoding","sampleRateHertz","languageCode","config","interimResults","recognizeStream","streamingRecognize","process","stdout","write","results","alternatives","transcript","record","threshold","verbose","recordProgram","silence","stream","pipe","App","onEnd","speak","voices","onResult","result","listen","listening","stop","devTools","recStart","lang","continuous","recStop","changeColour","document","body","style","background","ttsStart","effect","text","voice","ttsCancel","current","service","proxyurl","rasaurl","nluRequest","fetch","Request","method","headers","then","json","rootElement","getElementById","render"],"mappings":";;;;;;;;AAAA,OAAO,eAAP;AACA,OAAO,KAAKA,KAAZ,MAAuB,OAAvB;AACA,OAAO,KAAKC,QAAZ,MAA0B,WAA1B;AACA,SAASC,OAAT,EAAkBC,MAAlB,EAA0BC,OAA1B,QAAgD,QAAhD;MACQC,I,GAAiBD,O,CAAjBC,I;MAAMC,M,GAAWF,O,CAAXE,M;AACd,SAASC,UAAT,EAAqBC,QAArB,QAAqC,eAArC;AACA,SAASC,OAAT,QAAwB,iBAAxB;AACA,SAASC,SAAT,QAA0B,iBAA1B;AAGAD,OAAO,CAAC;AACJE,EAAAA,GAAG,EAAE,gCADD;AAEJC,EAAAA,MAAM,EAAE;AAFJ,CAAD,CAAP;AAKA,SAASC,kBAAT,EAA6BC,oBAA7B,QAAyD,kBAAzD;;AAGA,MAAMC,OAAO,GAAGb,OAAO,CAA4B;AAC/Cc,EAAAA,EAAE,EAAE,MAD2C;AAE/CC,EAAAA,IAAI,EAAE,UAFyC;AAG/CC,EAAAA,MAAM,EAAE;AACJC,IAAAA,EAAE,oBACKT,SADL,CADE;AAIJU,IAAAA,MAAM,EAAE;AACJC,MAAAA,OAAO,EAAE,MADL;AAEJH,MAAAA,MAAM,EAAE;AACJI,QAAAA,IAAI,EAAE;AACFC,UAAAA,EAAE,EAAE;AACAC,YAAAA,MAAM,EAAE,aADR;AAEAC,YAAAA,KAAK,EAAE;AACHC,cAAAA,MAAM,EAAE,UADL;AAEHtB,cAAAA,OAAO,EAAED,MAAM,CAAC,CAACwB,QAAD,EAAWC,KAAX,KAAqB;AAAE,uBAAO;AAAEC,kBAAAA,SAAS,EAAED,KAAK,CAACE;AAAnB,iBAAP;AAAmC,eAA3D;AAFZ;AAFP;AADF,SADF;AAUJC,QAAAA,WAAW,EAAE;AACTV,UAAAA,OAAO,EAAE,UADA;AAETW,UAAAA,KAAK,EAAE,UAFE;AAGTC,UAAAA,IAAI,EAAE,SAHG;AAITV,UAAAA,EAAE,EAAE;AACAW,YAAAA,SAAS,EAAE;AACP9B,cAAAA,OAAO,EAAE,CAAC,cAAD,EACLD,MAAM,CAAC,CAACwB,QAAD,EAAWC,KAAX,KAAqB;AAAE,uBAAO;AAAEO,kBAAAA,SAAS,EAAEP,KAAK,CAACE,KAAN,CAAYM,WAAZ;AAAb,iBAAP;AAAiD,eAAzE,CADD,CADF;AAGPV,cAAAA,MAAM,EAAE;AAHD,aADX;AAMAW,YAAAA,UAAU,EAAE;AAC7BjC,cAAAA,OAAO,EAAE,CACRE,MAAM,CAAC,kBAAD,CADE,CAER;AAFQ,eADoB;AAK7BoB,cAAAA,MAAM,EAAE;AALqB,aANZ;AAaAY,YAAAA,SAAS,EAAE,CACV;AAClB;AACA;AACA;AACkB;AACA;AACjBZ,cAAAA,MAAM,EAAC,MADU,CAEjB;;AAFiB,aANU;AAbX,WAJK;AA6BTR,UAAAA,MAAM,EAAE;AACJqB,YAAAA,QAAQ,EAAE,EADN;AAGJC,YAAAA,KAAK,EAAE;AACHR,cAAAA,KAAK,EAAE3B,IAAI,CAAC,YAAD;AADR;AAHH;AA7BC,SAVT;AA+CJoC,QAAAA,QAAQ,EAAE;AACNT,UAAAA,KAAK,EAAE,UADD;AAENT,UAAAA,EAAE,EAAE;AACAmB,YAAAA,SAAS,EAAE;AADX;AAFE;AA/CN;AAFJ;AAJJ;AAHuC,CAA5B,EAkEnB;AACItC,EAAAA,OAAO,EAAE;AACLuC,IAAAA,YAAY,EAAGC,OAAD,IAAyB;AACnC;AACAC,MAAAA,OAAO,CAACC,GAAR,CAAY,aAAaF,OAAO,CAACT,SAAjC;AACH,KAJI;AAKLY,IAAAA,IAAI,EAAE,MAAM;AACRF,MAAAA,OAAO,CAACC,GAAR,CAAY,MAAZ;AACH,KAPI;AAQLE,IAAAA,SAAS,EAAGJ,OAAD,IAAyB;AAChC;AACAC,MAAAA,OAAO,CAACC,GAAR,CAAY,oBAAoBF,OAAO,CAACK,OAAR,CAAgBC,MAAhB,CAAuBC,IAAvD;AACH;AAXI;AADb,CAlEmB,CAAvB;;AAuFA,MAAMC,cAAc,GAAIC,KAAD,IAA+B;AAClD,UAAQ,IAAR;AACI,SAAKA,KAAK,CAACC,KAAN,CAAYC,OAAZ,CAAoB;AAAEnC,MAAAA,MAAM,EAAE;AAAV,KAApB,CAAL;AACI,0BACI;AAAQ,QAAA,IAAI,EAAC,QAAb;AAAsB,QAAA,SAAS,EAAC,eAAhC;AACI,QAAA,KAAK,EAAE;AAAEoC,UAAAA,SAAS,EAAE;AAAb;AADX,SACoDH,KADpD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cADJ;;AAMJ,SAAKA,KAAK,CAACC,KAAN,CAAYC,OAAZ,CAAoB;AAAEnC,MAAAA,MAAM,EAAE;AAAV,KAApB,CAAL;AACI,0BACI;AAAQ,QAAA,IAAI,EAAC,QAAb;AAAsB,QAAA,SAAS,EAAC,eAAhC;AACI,QAAA,KAAK,EAAE;AAAEoC,UAAAA,SAAS,EAAE;AAAb;AADX,SACuDH,KADvD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cADJ;;AAMJ;AACI,0BACI;AAAQ,QAAA,IAAI,EAAC,QAAb;AAAsB,QAAA,SAAS,EAAC;AAAhC,SAAoDA,KAApD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cADJ;AAhBR;AAsBH,CAvBD;AAyBA;AACA;AACA;AACA;AACA;AACA;AACA;;;KA/BMD,c;;iBAiCQK,OAAO,CAAC,qBAAD,C;MAAdC,G,YAAAA,G;;AACP,MAAMC,IAAI,GAAGF,OAAO,CAAC,qBAAD,CAApB;;SAEeG,I;;;;;mEAAf;AAAA;AAAA;AAAA;AAAA;AACQC,UAAAA,MADR,GACiB,IAAIH,GAAJ,CAAQ;AACrBI,YAAAA,KAAK,EAAEH,IAAI,CAACI,YADS;AAErBC,YAAAA,GAAG,EAAEL,IAAI,CAACM,WAFW;AAGrBC,YAAAA,MAAM,EAAE,CAAC,gDAAD;AAHa,WAAR,CADjB;AAMQvD,UAAAA,GANR,wDAM4DgD,IAAI,CAACQ,UANjE;AAAA;AAAA,iBAOoBN,MAAM,CAACO,OAAP,CAAe;AAACzD,YAAAA;AAAD,WAAf,CAPpB;;AAAA;AAOQ0D,UAAAA,GAPR;AAQExB,UAAAA,OAAO,CAACC,GAAR,CAAYuB,GAAG,CAACC,IAAhB;;AARF;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AAWAV,IAAI,GAAGW,KAAP,CAAa1B,OAAO,CAAC2B,KAArB;;AAEA,MAAMC,QAAQ,GAAGhB,OAAO,CAAC,oBAAD,CAAxB,C,CAEA;;;AACA,MAAMiB,MAAM,GAAGjB,OAAO,CAAC,sBAAD,CAAtB,C,CAEA;;;AACA,MAAMI,MAAM,GAAG,IAAIa,MAAM,CAACC,YAAX,EAAf;AAGA,MAAMC,QAAQ,GAAG,UAAjB;AACA,MAAMC,eAAe,GAAG,KAAxB;AACA,MAAMC,YAAY,GAAG,OAArB;AAEA,MAAMV,OAAO,GAAG;AACdW,EAAAA,MAAM,EAAE;AACNH,IAAAA,QAAQ,EAAEA,QADJ;AAENC,IAAAA,eAAe,EAAEA,eAFX;AAGNC,IAAAA,YAAY,EAAEA;AAHR,GADM;AAMdE,EAAAA,cAAc,EAAE,KANF,CAMS;;AANT,CAAhB,C,CASA;;AACA,MAAMC,eAAe,GAAGpB,MAAM,CAC3BqB,kBADqB,CACFd,OADE,EAErB7C,EAFqB,CAElB,OAFkB,EAETsB,OAAO,CAAC2B,KAFC,EAGrBjD,EAHqB,CAGlB,MAHkB,EAGV+C,IAAI,IACda,OAAO,CAACC,MAAR,CAAeC,KAAf,CACEf,IAAI,CAACgB,OAAL,CAAa,CAAb,KAAmBhB,IAAI,CAACgB,OAAL,CAAa,CAAb,EAAgBC,YAAhB,CAA6B,CAA7B,CAAnB,4BACsBjB,IAAI,CAACgB,OAAL,CAAa,CAAb,EAAgBC,YAAhB,CAA6B,CAA7B,EAAgCC,UADtD,UAEI,sDAHN,CAJoB,CAAxB,C,CAWA;AACA;;AACAf,QAAQ,CACLgB,MADH,CACU;AACNZ,EAAAA,eAAe,EAAEA,eADX;AAENa,EAAAA,SAAS,EAAE,CAFL;AAGN;AACAC,EAAAA,OAAO,EAAE,KAJH;AAKNC,EAAAA,aAAa,EAAE,KALT;AAKgB;AACtBC,EAAAA,OAAO,EAAE;AANH,CADV,EASGC,MATH,GAUGvE,EAVH,CAUM,OAVN,EAUesB,OAAO,CAAC2B,KAVvB,EAWGuB,IAXH,CAWQd,eAXR;AAaApC,OAAO,CAACC,GAAR,CAAY,kCAAZ;;AAGA,SAASkD,GAAT,GAAe;AAAA;;AAAA,8BACiCnF,kBAAkB,CAAC;AAC3DoF,IAAAA,KAAK,EAAE,MAAM;AACT5F,MAAAA,IAAI,CAAC,WAAD,CAAJ;AACH;AAH0D,GAAD,CADnD;AAAA,QACH6F,KADG,uBACHA,KADG;AAAA,QACI5F,MADJ,uBACIA,MADJ;AAAA,QACYmC,QADZ,uBACYA,QADZ;AAAA,QACsB0D,MADtB,uBACsBA,MADtB;;AAAA,gCAMyBrF,oBAAoB,CAAC;AACrDsF,IAAAA,QAAQ,EAAGC,MAAD,IAAiB;AACvBhG,MAAAA,IAAI,CAAC;AAAEY,QAAAA,IAAI,EAAE,WAAR;AAAqBa,QAAAA,KAAK,EAAEuE;AAA5B,OAAD,CAAJ;AACAxD,MAAAA,OAAO,CAACC,GAAR,CAAYuD,MAAZ;AACH;AAJoD,GAAD,CAN7C;AAAA,QAMHC,MANG,yBAMHA,MANG;AAAA,QAMKC,SANL,yBAMKA,SANL;AAAA,QAMgBC,IANhB,yBAMgBA,IANhB;;AAAA,sBAYsBjG,UAAU,CAACQ,OAAD,EAAU;AACjD0F,IAAAA,QAAQ,EAAE,IADuC;AAEjDrG,IAAAA,OAAO,EAAE;AACLsG,MAAAA,QAAQ,EAAElG,QAAQ,CAAC,MAAM;AACrBqC,QAAAA,OAAO,CAACC,GAAR,CAAY,cAAZ;AACAwD,QAAAA,MAAM,CAAC;AAClBK,UAAAA,IAAI,EAAE,OADY;AAEH3B,UAAAA,cAAc,EAAE,KAFb;AAGH4B,UAAAA,UAAU,EAAE,IAHT,CAIH;;AAJG,SAAD,CAAN;AAMH,OARiB,CADb;AAULC,MAAAA,OAAO,EAAErG,QAAQ,CAAC,MAAM;AACpBqC,QAAAA,OAAO,CAACC,GAAR,CAAY,sBAAZ;AACA0D,QAAAA,IAAI;AACP,OAHgB,CAVZ;AAcLM,MAAAA,YAAY,EAAEtG,QAAQ,CAAEoC,OAAD,IAAa;AAChCC,QAAAA,OAAO,CAACC,GAAR,CAAY,eAAZ;AACAiE,QAAAA,QAAQ,CAACC,IAAT,CAAcC,KAAd,CAAoBC,UAApB,GAAiCtE,OAAO,CAACT,SAAzC;AACH,OAHqB,CAdjB;AAkBLgF,MAAAA,QAAQ,EAAE3G,QAAQ,CAAC,CAACoC,OAAD,EAAUwE,MAAV,KAAqB;AACpCvE,QAAAA,OAAO,CAACC,GAAR,CAAY,aAAZ;AACAoD,QAAAA,KAAK,CAAC;AACjBmB,UAAAA,IAAI,EAAEzE,OAAO,CAACf,SADG;AAEjByF,UAAAA,KAAK,EAAEnB,MAAM,CAAC,CAAD;AAFI,SAAD,CAAL;AAIH,OANiB,CAlBb;AAyBLoB,MAAAA,SAAS,EAAE/G,QAAQ,CAAC,CAACoC,OAAD,EAAUwE,MAAV,KAAqB;AACrCvE,QAAAA,OAAO,CAACC,GAAR,CAAY,aAAZ;AACAxC,QAAAA,MAAM;AACT,OAHkB;AAInB;AACZ;AACA;AACA;;AAhCiB;AAFwC,GAAV,CAZhC;AAAA;AAAA,QAYJkH,OAZI;AAAA,QAYKnH,IAZL;AAAA,QAYWoH,OAZX;;AAmDX,sBACI;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA,4BACL;AAAI,MAAA,SAAS,EAAC,SAAd;AAAA,gBACCD,OAAO,CAAC5E,OAAR,CAAgBf,SAAhB,IAA6B;AAD9B;AAAA;AAAA;AAAA;AAAA,YADK,eAII,QAAC,cAAD;AAAgB,MAAA,KAAK,EAAE2F,OAAvB;AAAgC,MAAA,OAAO,EAAE,MAAMnH,IAAI,CAAC,OAAD;AAAnD;AAAA;AAAA;AAAA;AAAA,YAJJ;AAAA;AAAA;AAAA;AAAA;AAAA,UADJ;AAQH;;GA3DQ2F,G;UACuCnF,kB,EAKRC,oB,EAMHP,U;;;MAZ5ByF,G;AA2DR,C,CAGE;AAEH;;AAEA,MAAM0B,QAAQ,GAAG,sCAAjB;AACA,MAAMC,OAAO,GAAG,kDAAhB;;AACA,MAAMC,UAAU,GAAIP,IAAD,IACfQ,KAAK,CAAC,IAAIC,OAAJ,CAAYJ,QAAQ,GAAGC,OAAvB,EAAgC;AAClCI,EAAAA,MAAM,EAAE,MAD0B;AAElCC,EAAAA,OAAO,EAAE;AAAE,cAAU;AAAZ,GAFyB;AAES;AAC3ChB,EAAAA,IAAI,yBAAeK,IAAf;AAH8B,CAAhC,CAAD,CAAL,CAKKY,IALL,CAKU3D,IAAI,IAAIA,IAAI,CAAC4D,IAAL,EALlB,CADJ;;AAQA,MAAMC,WAAW,GAAGpB,QAAQ,CAACqB,cAAT,CAAwB,MAAxB,CAApB;AACAnI,QAAQ,CAACoI,MAAT,eACI,QAAC,GAAD;AAAA;AAAA;AAAA;AAAA,QADJ,EAEIF,WAFJ","sourcesContent":["import \"./styles.scss\";\nimport * as React from \"react\";\nimport * as ReactDOM from \"react-dom\";\nimport { Machine, assign, actions, State } from \"xstate\";\nconst { send, cancel } = actions;\nimport { useMachine, asEffect } from \"@xstate/react\";\nimport { inspect } from \"@xstate/inspect\";\nimport { dmMachine } from \"./final_project\"; \nimport potato from './potatis.jpeg';\n\ninspect({\n    url: \"https://statecharts.io/inspect\",\n    iframe: false\n});\n\nimport { useSpeechSynthesis, useSpeechRecognition } from 'react-speech-kit';\n\n\nconst machine = Machine<SDSContext, any, SDSEvent>({\n    id: 'root',\n    type: 'parallel',\n    states: {\n        dm: {\n            ...dmMachine\n        },\n        asrtts: {\n            initial: 'idle',\n            states: {\n                idle: {\n                    on: {\n                        LISTEN: 'recognising',\n                        SPEAK: {\n                            target: 'speaking',\n                            actions: assign((_context, event) => { return { ttsAgenda: event.value } })\n                        }\n                    }\n                },\n                recognising: {\n                    initial: 'progress',\n                    entry: 'recStart',\n                    exit: 'recStop',\n                    on: {\n                        ASRRESULT: {\n                            actions: ['recLogResult',\n                                assign((_context, event) => { return { recResult: event.value.toLowerCase() } })],\n                            target: '.match'\n                        },\n                        RECOGNISED: {\n\t\t\t\t\t\t\tactions: [\n\t\t\t\t\t\t\t\tcancel('maxspeech_cancel'),\n\t\t\t\t\t\t\t\t//assign((_context, event) => { return { maxspeech_count: 0 } })\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\ttarget: 'idle'\n\t\t\t\t\t\t},\n                        MAXSPEECH: [\n\t                        //{\n\t\t\t\t\t\t\t//\tcond: context=> context.maxspeech_count < 2,\n\t\t\t\t\t\t\t//\ttarget:'idle',\n\t\t\t\t\t\t\t//\tactions: assign((_context, event) => { return { maxspeech_count: _context.maxspeech_count +1 } }),\n\t                        //},\n\t                        {\n\t\t\t\t\t\t\t\ttarget:'idle',\n\t\t\t\t\t\t\t\t//actions: assign((_context, event) => { return { maxspeech_count: 0 } }),\n\t                        },\n\t                    ]\n                    },\n                    states: {\n                        progress: {\n                        },\n                        match: {\n                            entry: send('RECOGNISED'),\n                        },\n                    }\n                },\n                speaking: {\n                    entry: 'ttsStart',\n                    on: {\n                        ENDSPEECH: 'idle',\n                    }\n                }\n            }\n        }\n    },\n},\n    {\n        actions: {\n            recLogResult: (context: SDSContext) => {\n                /* context.recResult = event.recResult; */\n                console.log('<< ASR: ' + context.recResult);\n            },\n            test: () => {\n                console.log('test')\n            },\n            logIntent: (context: SDSContext) => {\n                /* context.nluData = event.data */\n                console.log('<< NLU intent: ' + context.nluData.intent.name)\n            }\n        },\n    });\n\n\n\ninterface Props extends React.HTMLAttributes<HTMLElement> {\n    state: State<SDSContext, any, any, any>;\n}\nconst ReactiveButton = (props: Props): JSX.Element => {\n    switch (true) {\n        case props.state.matches({ asrtts: 'recognising' }):\n            return (\n                <button type=\"button\" className=\"glow-on-hover\"\n                    style={{ animation: \"glowing 20s linear\" }} {...props}>\n                    Listening...\n                </button>\n            );\n        case props.state.matches({ asrtts: 'speaking' }):\n            return (\n                <button type=\"button\" className=\"glow-on-hover\"\n                    style={{ animation: \"bordering 1s infinite\" }} {...props}>\n                    Speaking...\n                </button>\n            );\n        default:\n            return (\n                <button type=\"button\" className=\"glow-on-hover\" {...props}>\n                    Click to start\n                </button >\n            );\n    }\n}\n\n/*\nvar SpeechGrammarList = SpeechGrammarList || webkitSpeechGrammarList\nvar letters = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z'];\nvar grammar = '#JSGF V1.0; grammar letters; public <letter> = ' + letters.join(' | ') + ' ;'\nvar speechRecognitionList = new SpeechGrammarList();\nspeechRecognitionList.addFromString(grammar, 1);\n*/\n\nconst {JWT} = require('google-auth-library');\nconst keys = require('./el_goog_cred.json');\n\nasync function main() {\n  const client = new JWT({\n    email: keys.client_email,\n    key: keys.private_key,\n    scopes: ['https://www.googleapis.com/auth/cloud-platform'],\n  });\n  const url = `https://dns.googleapis.com/dns/v1/projects/${keys.project_id}`;\n  const res = await client.request({url});\n  console.log(res.data);\n}\n\nmain().catch(console.error);\n\nconst recorder = require('node-record-lpcm16');\n\n// Imports the Google Cloud client library\nconst speech = require('@google-cloud/speech');\n\n// Creates a client\nconst client = new speech.SpeechClient();\n\n\nconst encoding = 'LINEAR16';\nconst sampleRateHertz = 16000;\nconst languageCode = 'en-AU';\n\nconst request = {\n  config: { \n    encoding: encoding,\n    sampleRateHertz: sampleRateHertz,\n    languageCode: languageCode,\n  },\n  interimResults: false, // If you want interim results, set this to true\n};\n\n// Create a recognize stream\nconst recognizeStream = client\n  .streamingRecognize(request)\n  .on('error', console.error)\n  .on('data', data =>\n    process.stdout.write(\n      data.results[0] && data.results[0].alternatives[0]\n        ? `Transcription: ${data.results[0].alternatives[0].transcript}\\n`\n        : '\\n\\nReached transcription time limit, press Ctrl+C\\n'\n    )\n  );\n\n// Start recording and send the microphone input to the Speech API.\n// Ensure SoX is installed, see https://www.npmjs.com/package/node-record-lpcm16#dependencies\nrecorder\n  .record({\n    sampleRateHertz: sampleRateHertz,\n    threshold: 0,\n    // Other options, see https://www.npmjs.com/package/node-record-lpcm16#options\n    verbose: false,\n    recordProgram: 'rec', // Try also \"arecord\" or \"sox\"\n    silence: '10.0',\n  })\n  .stream()\n  .on('error', console.error)\n  .pipe(recognizeStream);\n\nconsole.log('Listening, press Ctrl+C to stop.');\n\n\nfunction App() {\n    const { speak, cancel, speaking, voices } = useSpeechSynthesis({\n        onEnd: () => {\n            send('ENDSPEECH');\n        },\n    });\n    const { listen, listening, stop } = useSpeechRecognition({\n        onResult: (result: any) => {\n            send({ type: \"ASRRESULT\", value: result });\n            console.log(result)\n        },\n    });\n    const [current, send, service] = useMachine(machine, {\n        devTools: true,\n        actions: {\n            recStart: asEffect(() => {\n                console.log('LETS GOOOOOO');\n                listen({\n\t\t\t\t\tlang: 'en-AU',\n                    interimResults: false,\n                    continuous: true,\n                    //grammars: speechRecognitionList,\n                });\n            }),\n            recStop: asEffect(() => {\n                console.log('Recognition stopped.');\n                stop()\n            }),\n            changeColour: asEffect((context) => {\n                console.log('Repainting...');\n                document.body.style.background = context.recResult;\n            }),\n            ttsStart: asEffect((context, effect) => {\n                console.log('Speaking...');\n                speak({ \n\t\t\t\t\ttext: context.ttsAgenda,\n\t\t\t\t\tvoice: voices[0]\n\t\t\t\t})\n            }),\n            ttsCancel: asEffect((context, effect) => {\n                console.log('TTS STOP...');\n                cancel()\n            })\n            /* speak: asEffect((context) => {\n\t     * console.log('Speaking...');\n             *     speak({text: context.ttsAgenda })\n             * } */\n        }\n    });\n\n\n    return (\n        <div className=\"App\">\n\t\t\t<h1 className=\"scoring\">\n\t\t\t{current.context.ttsAgenda || 'Welcome'}\n\t\t\t</h1>\n            <ReactiveButton state={current} onClick={() => send('CLICK')} />\n        </div>\n    )\n};\n\n\n\t\t\t//<img src={potato} alt=\"potato\" height={300} width={200} />\n\n//RASA\n\nconst proxyurl = \"https://cors-anywhere.herokuapp.com/\";\nconst rasaurl = 'https://rasajacobcoles.herokuapp.com/model/parse'\nconst nluRequest = (text: string) =>\n    fetch(new Request(proxyurl + rasaurl, {\n        method: 'POST',\n        headers: { 'Origin': 'http://maraev.me' }, // only required with proxy\n        body: `{\"text\": \"${text}\"}`\n    }))\n        .then(data => data.json());\n\nconst rootElement = document.getElementById(\"root\");\nReactDOM.render(\n    <App />,\n    rootElement);\n"]},"metadata":{},"sourceType":"module"}